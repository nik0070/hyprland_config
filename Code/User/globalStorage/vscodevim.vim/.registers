{"version":"1.0","registers":[["%",[{"text":"","registerMode":0}]],["#",[{"text":"scraper/zero_scraper.py","registerMode":0}]],[".",[{"text":{"commandList":["<Esc>"],"actionKeys":[],"waitingForAnotherActionKey":false,"actionsRun":[{"name":"","isJump":false,"createsUndoPoint":false,"preservesDesiredColumn":false,"keysPressed":["i"],"actionType":"command","isCompleteAction":true,"runsOnceForEachCountPrefix":false,"modes":[0],"keys":[["i"],["<Insert>"]],"multicursorIndex":0},{"name":"","isJump":false,"createsUndoPoint":false,"preservesDesiredColumn":false,"keysPressed":["s","c","r","a","p","e","r","/"],"actionType":"command","isCompleteAction":true,"runsOnceForEachCountPrefix":false,"modes":[],"keys":[],"contentChanges":[{"text":"scraper/","range":[{"line":52,"character":15},{"line":52,"character":15}],"rangeOffset":1654,"rangeLength":0}],"cursorStart":{"line":52,"character":15},"cursorEnd":{"line":52,"character":23}},{"name":"","isJump":false,"createsUndoPoint":false,"preservesDesiredColumn":false,"keysPressed":["<Esc>"],"actionType":"command","isCompleteAction":true,"runsOnceForEachCountPrefix":false,"modes":[1],"keys":[["<Esc>"],["<C-c>"],["<C-[>"]]}],"actionsRunPressedKeys":["i","s","c","r","a","p","e","r","/","<Esc>"],"bufferedKeys":[],"allowPotentialRemapOnFirstKey":true,"hasRunOperator":false,"isInsertion":true,"transformer":{"transformations":[]},"count":0,"operatorCount":0,"registerKey":"","registerName":"\""},"registerMode":0}]],["\"",[{"registerMode":1,"text":"def main():\n    print('hello world ! Zero 1 Scraper')\n\nif __name__==\"__main__\":\n    main()"}]],["-",[{"text":"/home/nik/Pictures/wallpapers/Night /home/nik/Pictures/wallpapers/Night","registerMode":0}]],["0",[{"text":"from langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain_google_genai import GoogleGenerativeAI\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\napi_key = os.getenv('GEMINI_API_KEY')\n\nllm = GoogleGenerativeAI(\n        model=\"gemini-1.5-flash\",\n        google_api_key=api_key\n)\n\ndef prod_slogan(keyword):\n\n    chat_prompt = PromptTemplate.from_template(\n        input_variables = ['keyword'],\n        template = \"Can you give a slogan for the product after semicolon : {keyword}\"\n        )\n    \n    chain = chat_prompt | llm | StrOutputParser()\n    response = chain.invoke({'keyword': keyword})\n    return response \n\nif __name__ == \"__main__\":\n    prod_slogan('salty toothpaste')\n","registerMode":1}]],["*",[{"text":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport time\n\nBASE_URL = \"https://zerodha.com\"\n\ndef get_sector_links():\n    url = f\"{BASE_URL}/markets/sector/\"\n    resp = requests.get(url)\n    soup = BeautifulSoup(resp.text, \"html.parser\")\n\n    sector_links = []\n    for a in soup.select(\"a[href*='/markets/sector/']\"):\n        href = a.get(\"href\")\n        if href and href.startswith(\"/markets/sector/\") and href != \"/markets/sector/\":\n            sector_links.append(BASE_URL + href)\n    return list(set(sector_links))  # remove duplicates\n\ndef scrape_sector(url):\n    resp = requests.get(url)\n    soup = BeautifulSoup(resp.text, \"html.parser\")\n\n    # sector name from URL last part\n    sector_name = url.split(\"/\")[-1].replace(\"-\", \" \").title()\n\n    data = []\n    rows = soup.select(\"table tbody tr\")\n    for row in rows:\n        cols = [c.get_text(strip=True) for c in row.find_all(\"td\")]\n        if len(cols) >= 3:\n            company = cols[0]\n            market_cap = cols[1]\n            pe_ratio = cols[2]\n            data.append([sector_name, company, market_cap, pe_ratio])\n    return data\n\ndef main():\n    all_data = []\n    sector_links = get_sector_links()\n\n    print(f\"Found {len(sector_links)} sectors\")\n    for link in sector_links:\n        try:\n            sector_data = scrape_sector(link)\n            all_data.extend(sector_data)\n            print(f\"Scraped {len(sector_data)} companies from {link}\")\n            time.sleep(1)  # be gentle\n        except Exception as e:\n            print(f\"Error scraping {link}: {e}\")\n\n    df = pd.DataFrame(all_data, columns=[\"sector\", \"company\", \"market_cap\", \"PE\"])\n    df.to_csv(\"zerodha_sectors.csv\", index=False)\n    print(\"Saved to zerodha_sectors.csv\")\n\nif __name__ == \"__main__\":\n    main()\n","registerMode":0}]],["1",[{"text":"def main():\n    print('hello world ! Zero 1 Scraper')\n\nif __name__==\"__main__\":\n    main()","registerMode":1}]]]}